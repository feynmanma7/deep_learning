{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Optimization</h1>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dropout\n",
    "\n",
    "参考文献：\n",
    "\n",
    "[1] Dropout: A Simple Way to Prevent Neural Networks from Overfitting\n",
    "\n",
    "\n",
    "神经网络：\n",
    "\n",
    "共$L$层，每一层输入$\\boldsymbol{z^{(l)}}$，输出$\\boldsymbol{y^{(l)}}$，激活函数$f^{(l)}$，每一层节点个数$Q(l)$， $l\\in \\{0,1,...,L\\}$\n",
    "\n",
    "第$l$层到第$l+1$层的权重为$\\boldsymbol{W^{(l)}}$，偏置为$\\boldsymbol{b}^{(l)}$，$l\\in \\{0,1,...,L-1\\}$\n",
    "\n",
    "## a. 第$l+1$层输出\n",
    "\n",
    "> $z_i^{(l+1)} = \\boldsymbol{w}_i^{(l)}\\boldsymbol{y}^{(l)} + \\boldsymbol{b}_i^{(l)}\n",
    "= \\sum_{j=1}^{Q(l)}\n",
    "\\{w_{ji}^{(l)}y_j^{(l)}+b_i^{(l)}\\}$\n",
    "\n",
    "> $y_i^{(l+1)} = f^{(l+1)}(z_i^{(l+1)})$\n",
    "\n",
    "\n",
    "## b. Dropout 第$l+1$层输出\n",
    "\n",
    "假设每个节点的保留概率为$p$，\n",
    "\n",
    "> $r_i^{(l)} \\sim Bernoulli(p)$\n",
    "\n",
    "> $\\widetilde{\\boldsymbol{y}}_i^{(l)} =\n",
    "r_i^{(l)} * \\widetilde{\\boldsymbol{y}}_i^{(l)}$\n",
    "\n",
    "> $z_i^{(l+1)} = \\boldsymbol{w}_i^{(l)} \\widetilde{\\boldsymbol{y}}_i^{(l)} \n",
    "+ \\boldsymbol{b}_i^{(l)}$\n",
    "\n",
    "> $y_i^{(l+1)} = f^{(l+1)}(z_i^{(l+1)})$\n",
    "\n",
    "### (1) 训练数据权重不变，测试数据权重变化\n",
    "\n",
    "训练数据权重不变，每个节点以概率$p$保留，测试数据权重\n",
    "\n",
    "> $W_{test} = W_{train} * p$\n",
    "\n",
    "### (2) 训练数据权重变化，测试数据权重不变\n",
    "\n",
    "> $W_{train} = W_{train} * \\frac{1}{p}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 梯度下降 Gradient Descent\n",
    "\n",
    "## 损失函数\n",
    "\n",
    "> $J(\\theta) = \\sum_{i=1}^{N}L(f(x_i;\\theta), y)$\n",
    "\n",
    "## 优化目标\n",
    "> $\\theta^{*} = \\arg\\min_{\\theta}J(\\theta)$\n",
    "\n",
    "## 梯度下降\n",
    "根据泰勒展开，\n",
    "\n",
    "> $f(x+\\epsilon) \\approx f(x) + \\epsilon f(x)$\n",
    "\n",
    "对于特别小的$\\epsilon$，\n",
    "\n",
    "> $f(x - \\epsilon * sign(f'(x)) \\approx f(x) - \\epsilon * sign (f'(x))$\n",
    "\n",
    "如果$\\epsilon$与$sign(f'(x))$同号，即$x$按照$sign(f'(x))$的反反向移动一小步$\\epsilon$，能让$f(x)$的值有所下降，\n",
    "\n",
    "> $f(x - \\epsilon * sign(f'(x)) < f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
