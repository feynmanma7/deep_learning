{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>变分推断 Variational Inference</h1>\n",
    "\n",
    "<b>参考资料</b>\n",
    "\n",
    "[1] An Introduction to Variational Methods for Graphical Models, Jordan etc. 1999.\n",
    "\n",
    "[2] Variational Inference- Foundations and Modern Methods, Blei etc. NIPS Tutorial, 2016.\n",
    "\n",
    "[3] Pattern Recognition and Machine Learning, Chapter 10, Bishop, 2006.\n",
    "\n",
    "[4] Variational Inference: A Review for Statisticians, Blei etc. 2017.\n",
    "\n",
    "\n",
    "# 0. 概率机器学习\n",
    "\n",
    "## 0.0 概率模型\n",
    "\n",
    "给定可观测变量$x$与隐含变量$z$， 概率模型考虑$x$与$z$的联合分布，\n",
    "\n",
    "> $p(x, z)$\n",
    "\n",
    "## 0.1 推断\n",
    "\n",
    "给定观测变量，推断隐含变量$z$的后验概率分布$p(z|x)$，\n",
    "\n",
    "> $p(z|x) = \\frac{p(x, z)}{p(x)}$\n",
    "\n",
    "给定$z$之后，$p(x, z)$的计算是比较容易的；如在GMM中知道每个样本点属于每个类的概率，则可以计算完整数据$(x, z)$的似然。\n",
    "\n",
    "但是不完整数据$x$的似然$p(x) = \\int_z p(x, z) dz$，是难以计算的；如在GMM中，需要遍历每个样本点属于每个类的概率空间。\n",
    "\n",
    "因此需要采用一些近似推断的方式来计算$p(x)$，一般包括（1）抽样方法；（2）变分推断。本文关注<b>变分推断</b>。\n",
    "\n",
    "# 1. 变分推断 Variational Inference\n",
    "\n",
    "变分推断是一个确定性的近似推断方式，在有限元分析、量子力学、统计力学以及统计学等领域有着广泛的应用。\n",
    "\n",
    "基本思想：将复杂问题（intratable）转变为简单问题，降低原始问题的自由度(degrees of freedom)。\n",
    "\n",
    "# 1.0 ELBO (Evidence Lower BOund)\n",
    "\n",
    "隐变量$Z$的后验分布$p(Z|X)$难以计算（intractable），用一个好计算的分布$q(Z)$来尽可能接近$p(Z|X)$。即，最小化KL散度，\n",
    "\n",
    "> $q^*(Z) = \\arg\\max_{q(Z) \\in \\mathcal{A}} \\mathbb{KL}[q(Z)||p(Z|X)] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $ \\mathbb{KL}[q(Z)||p(Z|X)] $\n",
    "\n",
    "> $ = \\mathbb{E}_q[\\log q(Z) - \\log p(Z|X)]$\n",
    "\n",
    "> $ = \\mathbb{E}_q[\\log q(Z) - \\log p(Z, X)] + \\log p(X)$\n",
    "\n",
    "> $ = \\mathbb{E}_q[\\log q(Z)] - \\mathbb{E}_q[\\log p(Z, X)] + \\log p(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "从而，\n",
    "> $ \\log p(X) = \\mathbb{KL}[q(Z)||p(Z|X)] +\n",
    "\\underbrace{\n",
    "\\mathbb{E}_q[\\log p(Z, X)] - \\mathbb{E}_q[\\log q(Z)]}_{ELBO(q)}$\n",
    "\n",
    "> $ = \\mathbb{KL}[q(Z)||p(Z|X)] + ELBO(q)$\n",
    "\n",
    "> $ \\geqslant ELBO(q)$\n",
    "\n",
    "最小化KL散度，等价于最大化$ELBO(q)$，可以让$ELBO(q)$更接近$\\log p(X)$，此时$q^*(Z) = p(Z|X)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> $ ELBO(q) = \\mathbb{E}_q[\\log p(Z, X)] - \\mathbb{E}_q[\\log q(Z)] $\n",
    "\n",
    "> $ = \\mathbb{E}_q[\\log p(X|Z)] + \\mathbb{E}_q[\\log p(Z)] - \\mathbb{E}_q[\\log q(Z)]$\n",
    "\n",
    "> $ = \\mathbb{E}_q[\\log p(X|Z)] - \\mathbb{KL}[q(Z)||p(Z)] $\n",
    "\n",
    "最大化$ELBO(q)$等价于最大化似然$\\mathbb{E}_q[\\log p(X|Z)]$，并且最小化$\\mathbb{KL}[q(Z)||p(Z)]$，此时$q^*(Z) = p(Z)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 The Mean-field Variational Family\n",
    "\n",
    "假设隐变量之间相互独立，并且受不同的因子影响。则通用的平均场变分族为：\n",
    "\n",
    "> $q(\\boldsymbol{z}) = \\prod_{j=1}^{m}q_j(z_j)$\n",
    "\n",
    "每一个隐变量$z_j$都受它自己的变分因子$q_j(z_j)$影响。\n",
    "\n",
    "# 1.2 Coordinate ascent mean-field variational inference\n",
    "\n",
    "> $ ELBO(q) = \\mathbb{E}_q[\\log p(Z, X)] - \\mathbb{E}_q[\\log q(Z)] $\n",
    "\n",
    "考虑$ELBO(q_j)$，\n",
    "\n",
    "> $ ELBO(q_j) = \\mathbb{E}_{q_j}[ \\mathbb{E}_{q_{-j}} [\\log p(z_j, \\boldsymbol{z}_{-j}, x)] ]\n",
    "- \\mathbb{E}_{q_j}[\\log q_j(z_j)] + const$\n",
    "\n",
    "> $ = - \\mathbb{KL}[q_j(z_j)||q^*_j(z_j)]$ \n",
    "\n",
    "最大化$ELBO(q_j)$等价于最小化$\\mathbb{KL}[q_j(z_j)||q^*_j(z_j)]$，此时$q^*_j(z_j) = q_j(z_j)$。\n",
    "\n",
    "坐标上升平均场变分推断CAVI(Bishop2006)，依次迭代优化平均场变分密度的每一个因子（每次迭代时，固定除该因子之外的其它因子），最终得到ELBO的局部最优解。\n",
    "\n",
    "> $q^*_j(z_j) \\propto \\exp\\{\\mathbb{E}_{-j}[\\log p(z_j|\\boldsymbol{z}_{-j}, \\boldsymbol{x})]\\}$\n",
    "\n",
    "> $ = \\exp\\{\\mathbb{E}_{-j}[\\log p(z_j, \\boldsymbol{z}_{-j}, \\boldsymbol{x}) - \n",
    "\\log p(\\boldsymbol{z}_{-j}, \\boldsymbol{x})] \\}$\n",
    "\n",
    "> $ = \\exp\\{ \\mathbb{E}_{-j}[\\log p(z_j, \\boldsymbol{z}_{-j}, \\boldsymbol{x}) - \n",
    "\\underbrace{\n",
    " \\mathbb{E}_{-j}[\\log p(\\boldsymbol{z}_{-j}, \\boldsymbol{x})]}_{\\log p(\\boldsymbol{z}_{-j}, \\boldsymbol{x})} \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，\n",
    "> $q^*_j(z_j) \\propto \\exp \\{\\mathbb{E}_{-j}[\\log p(z_j, \\boldsymbol{z}_{-j}, \\boldsymbol{x})]\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CAVI算法</b>\n",
    "\n",
    "+ Input: 一个模型$p(X, Z)$，数据集$X$\n",
    "\n",
    "+ Output: 一个平均场变分概率密度函数$q(\\boldsymbol{z}) = \\prod_{j=1}^{m}q_j(z_j)$\n",
    "\n",
    "+ Initialize:  变分因子$q_j(z_j)$\n",
    "\n",
    "+ while ELBO(q) 没有收敛：<br>\n",
    "    for $j \\in \\{1,...,m\\}$ <br> \n",
    "    令$q_j(z_j) \\propto \\exp \\{\\mathbb{E}_{-j}[\\log p(z_j, \\boldsymbol{z}_{-j}, \\boldsymbol{x})]\\}$ <br>\n",
    "    End\n",
    "    \n",
    "+ 计算$ELBO(q) = \\mathbb{E}_q[\\log p(Z, X)] - \\mathbb{E}_q[\\log q(Z)]$。\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 CAVI示例\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
