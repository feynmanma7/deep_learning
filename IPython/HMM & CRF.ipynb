{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>HMM & CRF</h1>\n",
    "\n",
    "# 0. HMM\n",
    "\n",
    "线性回归、逻辑回归假设输入样本的变量（特征）之间是相互独立的，朴素贝叶斯假设特征之间是条件独立的，在现实中，提前到的特征之间往往有千丝万缕的联系，按照这些朴素的假设建模会损失很多信息。比如图像（按照像素表示）的相邻像素之间比较相似，一篇文章相邻的单词、句子、段落之间也有一定的时间序列上的关联性。\n",
    "\n",
    "为了建模变量之间的关联性，衍生了概率图模型。\n",
    "\n",
    "按照顶点之间的边是否有向，概率图模型分为有向概率图模型（如贝叶斯网络）和无向概率图模型（如条件随机场）。如果顶点之间关联的边特别多（如全连通图），会给计算带来特别大的麻烦。所以为了降低计算复杂度，会尽量选择结合物理意义和物理假设，建立条件独立关系、最大子团关系等来减少不必要的连通边。\n",
    "\n",
    "## 0.0 HMM定义\n",
    "\n",
    "隐马尔科夫模型(Hidden Markov Models)建模时间序列，假设有隐含变量按照一定的概率来生成特征变量，并且隐含变量之间也以一定的概率相互转移。\n",
    "\n",
    "$N$个输出节点，$N$个隐含节点的HMM包含隐含状态$K$个隐含状态$z_n=s_k$；\n",
    "\n",
    "> 隐含状态的初始概率分布为$\\pi$；\n",
    "\n",
    "> 隐含状态之间的状态转移概率矩阵为$A_{ij} = p(z_{n}=s_j|z_{n-1} = s_i)$；\n",
    "\n",
    "> 隐含状态到输出之间的输出观测概率矩阵为$B_{ij} = p(o_{n} = x_j|z_{n} = s_i)$。\n",
    "\n",
    "\n",
    "## 0.1 HMM问题\n",
    "\n",
    "+ Likelihood\n",
    "\n",
    "> 给定HMM模型$\\lambda=[\\pi, A, B]$和观测序列$X = \\{x_1, x_2, ..., x_n\\}$，求该序列的概率$p(X|\\lambda)$;\n",
    "\n",
    "+ Decode\n",
    "\n",
    "> 给定HMM模型$\\lambda=[\\pi, A, B]$和观测序列$X = \\{x_1, x_2, ..., x_n\\}$，给出最有可能的隐含状态序列$Z = \\{z_1, z_2, ..., z_n\\}$;\n",
    "\n",
    "+ Inference\n",
    "\n",
    "> 给定观测序列$X = \\{x_1, x_2, ..., x_n\\}$，如何调整模型参数$\\lambda = [\\pi, A, B]$，使得该序列出现的概率$p(X|\\lambda)$最大？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
