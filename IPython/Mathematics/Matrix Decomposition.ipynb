{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Matrix Decomposition</h1>\n",
    "# 0. Matrix\n",
    "\n",
    "\n",
    "## 0.0 Left & Right Multiplication\n",
    "Left multiplication a Matrix modifies the rows of the Matrix;\n",
    "\n",
    "Right multiplication a Matrix modifies the columns of the Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 6]\n",
      " [1 2 3]\n",
      " [7 8 9]]\n",
      "[[2 1 3]\n",
      " [5 4 6]\n",
      " [8 7 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "B = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "\n",
    "print(B.dot(A))\n",
    "print(A.dot(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Matrix Derivative\n",
    "\n",
    "Note: There are two different kind of ways to layout, numerator and denominator.\n",
    "\n",
    "+ Numerator Layout\n",
    "\n",
    "> The <b>row number</b> of result is the same with the column number of numerator, \n",
    "\n",
    "> and the column number of result is the same with the denominator.\n",
    "\n",
    "+ Denominator Layout\n",
    "\n",
    "> The <b>row number</b> of result is the same with the column number of denominator, \n",
    "\n",
    "> the column number of result is the same with the numerator.\n",
    "\n",
    "I choose the <b>denominator</b> way, which expands the column of numerator in a row. \n",
    "\n",
    "\n",
    "### 0.1.0 Vector by scalar\n",
    "\n",
    "> $\\frac{\\partial{\\vec{x}}}{\\partial{a}} \n",
    "= [\\frac{\\partial{x_1}}{\\partial{a}}, \n",
    "\\frac{\\partial{x_2}}{\\partial{a}},\n",
    "...,\n",
    "\\frac{\\partial{x_n}}{\\partial{a}}]^T$\n",
    "\n",
    "### 0.1.1 Scalar by vector\n",
    "\n",
    "The column number of derivative result is 1, \n",
    "\n",
    "> $\\frac{\\partial{a}}{\\partial{\\vec{x}}}\n",
    "= [\\frac{\\partial{a}}{\\partial{x_1}}, \n",
    "\\frac{\\partial{a}}{\\partial{x_2}},\n",
    "...,\n",
    "\\frac{\\partial{a}}{\\partial{x_n}}]$\n",
    "\n",
    "### 0.1.2 Vector by vector\n",
    "\n",
    "The derivative result is the well-known Jacobbian Matrix.\n",
    "\n",
    "> $\\frac{\\partial{\\vec{y}}}{\\partial{\\vec{x}}} = [\n",
    "\\frac{\\partial{y_1}}{\\partial{\\vec{x}}}, \n",
    "\\frac{\\partial{y_2}}{\\partial{\\vec{x}}}, \n",
    "...,\n",
    "\\frac{\\partial{y_m}}{\\partial{\\vec{x}}}]^T$\n",
    "\n",
    "> $ = [\n",
    "[\\frac{\\partial{y_1}}{\\partial{\\vec{x_1}}}, \n",
    "\\frac{\\partial{y_1}}{\\partial{\\vec{x_2}}}, \n",
    "..., \n",
    "\\frac{\\partial{y_1}}{\\partial{\\vec{x_n}}}], \n",
    "[\\frac{\\partial{y_2}}{\\partial{\\vec{x_1}}}, \n",
    "\\frac{\\partial{y_2}}{\\partial{\\vec{x_2}}}, \n",
    "..., \n",
    "\\frac{\\partial{y_2}}{\\partial{\\vec{x_n}}}]\n",
    "...\n",
    "[\\frac{\\partial{y_m}}{\\partial{\\vec{x_1}}}, \n",
    "\\frac{\\partial{y_m}}{\\partial{\\vec{x_2}}}, \n",
    "..., \n",
    "\\frac{\\partial{y_m}}{\\partial{\\vec{x_n}}}]\n",
    "]^T$\n",
    "\n",
    "\n",
    "### 0.1.2 Vector multiplication by vector\n",
    "\n",
    "### 0.1.2.0 $\\vec{a}$ is not a function of $\\vec{x}$\n",
    "\n",
    "The result of $\\vec{x}^T \\vec{a}$ and $\\vec{a}^T \\vec{x}$ \n",
    "can be <b>assumed</b> to a scalar.\n",
    "\n",
    "Hence, the derivative result is a column vector.\n",
    "\n",
    "> $\\frac{\\partial{\\vec{x}^T \\vec{a}}}{\\partial{\\vec{x}}} =\n",
    "\\frac{\\partial{\\vec{a}^T \\vec{x}}}{\\partial{\\vec{x}}} = \\vec{a}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\frac{\\partial{\\vec{b}^T A \\vec{x}}}{\\partial{\\vec{x}}} = \n",
    "\\frac{ \\partial{ (A^T \\vec{b})^T } \\vec{x} } {\\partial{x}} =\n",
    "(A^T \\vec{b})^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.2.1 $u$ and $v$ is function of $\\vec{x}$\n",
    "\n",
    "$u$ and $v$ is scalar and function of $\\vec{x}$,\n",
    "$u = u(\\vec{x})$, $v = v(\\vec{x})$, \n",
    "\n",
    "> $\\frac{\\partial{u + v}}{\\partial{\\vec{x}}}\n",
    "= \\frac{\\partial{u}}{\\partial{\\vec{x}}}\n",
    "+ \\frac{\\partial{v}}{\\partial{\\vec{x}}}$\n",
    "\n",
    "> $\\frac{\\partial{u v}}{\\partial{\\vec{x}}} = \n",
    "u \\frac{\\partial{v}}{\\partial{\\vec{x}}} + \n",
    "v \\frac{\\partial{u}}{\\partial{\\vec{x}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The Most Important Equation</b>\n",
    "\n",
    "$\\vec{u}$ and $\\vec{v}$ is vector and function of $\\vec{x}$,\n",
    "$\\vec{u} = \\vec{u}(\\vec{x})$, $\\vec{v} = \\vec{v}(\\vec{x})$, \n",
    "\n",
    "> $\\frac{\\partial{(\\vec{u} \\bullet  \\vec{v}})}{\\partial{\\vec{x}}} = \n",
    "\\frac{\\partial{\\vec{u}^T \\vec{v}}}{\\partial{\\vec{x}}} = \n",
    "\\frac{\\partial{\\vec{u}}}{\\partial{\\vec{x}}} \\vec{v} + \n",
    "\\frac{\\partial{\\vec{v}}}{\\partial{\\vec{x}}} \\vec{u}\n",
    "$\n",
    "\n",
    "Note: Think of the expanding way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\frac{\\partial{\\vec{x}^T A \\vec{x}}}{\\partial{\\vec{x}}} = \n",
    "\\frac{\\partial{(A^T\\vec{x})^T \\vec{x}}}{\\partial{\\vec{x}}}, \n",
    "(\\vec{u} = A^T\\vec{x}, \\vec{v} = \\vec{x})$\n",
    "\n",
    "> $ = \\frac{\\partial{A^T\\vec{x}}}{\\partial{\\vec{x}}} \\vec{x} + \n",
    "\\frac{\\partial{\\vec{x}}}{\\partial{\\vec{x}}} A^T\\vec{x}$\n",
    "\n",
    "> $ = A \\vec{x} + A^T \\vec{x}$\n",
    "\n",
    "> $ = (A + A^T) \\vec{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LU Decomposition\n",
    "Decomposite a square matrix A to a <b>L</b>ower triangular matrix and an <b>U</b>pper triangular matrix.\n",
    "\n",
    "> $A = U * V$\n",
    "\n",
    "If the first row of A is zero, then $a_{0,0} = u_{0, 0} * v_{0,0} = 0$, \n",
    "\n",
    "thus either $u_{0, 0}$ or $v_{0, 0}$ will be zero, which means that either $U$ or $V$ will be sigular.\n",
    "\n",
    "Use a Permutation matrix $P$ to permutate $A$, then use the LU decomposition, \n",
    "\n",
    "> $P A = U * V$\n",
    "\n",
    "> $A = P^{-1} * U * V = P * U * V, P^{-1} = P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]]\n",
      "[[ 1.          0.          0.        ]\n",
      " [ 0.14285714  1.          0.        ]\n",
      " [ 0.57142857  0.5         1.        ]]\n",
      "[[  7.00000000e+00   8.00000000e+00   9.00000000e+00]\n",
      " [  0.00000000e+00   8.57142857e-01   1.71428571e+00]\n",
      " [  0.00000000e+00   0.00000000e+00  -1.58603289e-16]]\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "P, L, U = lu(A)\n",
    "print(P)\n",
    "print(L)\n",
    "print(U)\n",
    "\n",
    "B = P.dot(L).dot(U)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use <b>Gaussian Elimination</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. QR Decomposition\n",
    "\n",
    "Decomposite a non-square matrix $A$ to a Othogonal matrix $Q$ and an upper triangular matrix $R$. \n",
    "\n",
    "> $A = Q * R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "\n",
      "[[-0.16903085  0.89708523  0.40824829]\n",
      " [-0.50709255  0.27602622 -0.81649658]\n",
      " [-0.84515425 -0.34503278  0.40824829]]\n",
      "\n",
      "[[-5.91607978 -7.43735744]\n",
      " [ 0.          0.82807867]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "[[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [ 5.  6.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import qr\n",
    "\n",
    "A = np.array([[1, 2], [3, 4], [5, 6]]) # (3, 2)\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "Q, R = qr(A)\n",
    "print(Q)\n",
    "print()\n",
    "print(R)\n",
    "print()\n",
    "\n",
    "B = Q.dot(R)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume $\\{a_1, a_2, ..., a_n\\}$ are the columns of $A$, \n",
    "\n",
    "> $A = [a_1, a_2, ..., a_n]$\n",
    "\n",
    "Project vector $u$ onto vector $v$, the projection is defined as, \n",
    "\n",
    "> $prod_v(u) = ||u|| \\cos(u, b) b$\n",
    "\n",
    "> $= ||u|| \\frac{u^T b}{||u|| * ||b||} b$\n",
    "\n",
    "> $= u^T b * b$\n",
    "\n",
    "> $= u^T \\frac{v}{||v||} * \\frac{v}{||v||}$\n",
    "\n",
    "> $= \\frac{<u, v>}{<v, v>}v$\n",
    "\n",
    "> $b = \\frac{v}{||v||}, b^T b = b b^T = I, ||b|| = 1$\n",
    "\n",
    "Compute $\\{u_1, u_2, ..., u_n\\}$ as follows,\n",
    "\n",
    "> $u_1 = a_1, e_1 = \\frac{u_1}{||u_1||}$\n",
    "\n",
    "> $u_2 = a_2 - prod_{u_1}a_2, e_2 = \\frac{u_2}{||u_2||}$\n",
    "\n",
    "> $u_3 = a_3 - prod_{u_1}a_3 - prod_{u_2}a_3, e_3 = \\frac{u_3}{||u_3||}$\n",
    "\n",
    "> $...$\n",
    "\n",
    "> $u_n = a_n - \\sum_{j=1}^{n-1}prod_{u_j}a_n, e_n = \\frac{u_n}{||u_n||}$\n",
    "\n",
    "$\\Longrightarrow$\n",
    "\n",
    "> $a_1 = u_1 = prod_{e_1}u_1 = prod_{e_1}a_1 = \\frac{<a_1, e_1>}{<e_1, e_1>}e_1 = e_1 <a_1, e_1>, <e_1, e_1> = 1$\n",
    "\n",
    "> $a_2 = u_2 + prod_{u_1}a_2$\n",
    "\n",
    "> $= prod_{e_2}u_2 + prod_{e_1}a_2$\n",
    "\n",
    "> $= prod_{e_2}\\{a_2 - prod_{u_1}a_2\\} + prod_{e_1}a_2$\n",
    "\n",
    "> $= prod_{e_2} a_2 + prod_{e_1} a_2$\n",
    "\n",
    "> $= e_2<a_2, e_2> + e_1<a_2, e_1>$\n",
    "\n",
    "> $...$\n",
    "\n",
    "> $a_n = \\sum_{j=1}^n e_j<a_n, e_j>$\n",
    "\n",
    "Let $Q = [e_1, e_2, ..., e_n]$, $R = [r_1, r_2, ..., r_n]$, \n",
    "\n",
    "> $r_1 = [<a_1, e_1>, 0, ..., 0]$\n",
    "\n",
    "> $r_2 = [<a_2, e_1>, <a_2, e_2>, 0, ..., 0]$\n",
    "\n",
    "> $...$\n",
    "\n",
    "> $r_n = [<a_n, e_1>, <a_n, e_2>, ..., <a_n, e_n>]$\n",
    "\n",
    "Obtain the QR decomposition, \n",
    "\n",
    "> $A = Q * R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Cholesky Decomposition\n",
    "\n",
    "## 3.0 Cholesky Decomposition\n",
    "\n",
    "Reference:\n",
    "\n",
    "http://www.seas.ucla.edu/~vandenbe/133A/lectures/chol.pdf\n",
    "\n",
    "Every positive definite matrix can be factored as, \n",
    "\n",
    "> $A = L L^T$\n",
    "\n",
    "where $L$ is lower (or upper) triangular with positive diagonal components.\n",
    "\n",
    "Using matrix blocks, \n",
    "> $A = [[A_{1,1}, A_{1, 2:n}]^T, [A_{2:n,1}, A_{2:n,2:n}]^T]$\n",
    "\n",
    "> $=[[L_{1,1}, 0]^T, [L_{2:n, 1}, L_{2:n,2:n}]^T]$\n",
    "\n",
    "> $[[L_{1,1}, L_{2:n, 1}^T]^T, [0, L_{2:n,2:n}^T]^T]$\n",
    "\n",
    "> $= [[L_{1,1}^2, L_{1,1}L_{2:n, 1}^T]^T,\n",
    "[L_{2:n, 1} L_{1,1},\n",
    "L_{2:n, 1} L_{1,2}^T + L_{2:n,2:n}^T L_{2:n,2:n}]^T]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Longrightarrow$\n",
    "\n",
    "> $A_{1, 1} = L_{1, 1}^2$\n",
    "\n",
    "> $A_{1, 2:n} = L_{1, 1}L_{2:n, 1}^T$\n",
    "\n",
    "> $A_{2:n, 1} = L_{2:n, 1} L_{1,1}$\n",
    "\n",
    "> $A_{2:n, 2:n} = L_{2:n, 1} L_{2:n, 1}^T\n",
    "+ L_{2:n, 2:n} L_{2:n, 2:n}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Longrightarrow$\n",
    "\n",
    "> $L_{1, 1} = \\sqrt{A_{1, 1}}$\n",
    "\n",
    "> $L_{2:n, 1} = \\frac{A_{2:n, 1}}{L_{1,1}}$\n",
    "\n",
    "> $L_{2:n, 2:n} L_{2:n, 2:n}^T = A_{2:n, 2:n} - L_{2:n, 1} L_{2:n, 1}^T, (1)$\n",
    "\n",
    "Equation (1) is another cholesky factorization of \n",
    "$A_{2:n, 2:n} - L_{2:n, 1} L_{2:n, 1}^T$ with order $n-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate to solve all of the orders of cholesky decomposition.\n",
    "\n",
    "In order $k$, to compute the first column of current order,\n",
    "\n",
    "which is the $j$-th ($k + j = n$) column of the original matrix $A$, \n",
    "\n",
    "In the current order, the current matrix becomes,\n",
    "\n",
    "> $A_{i, i} = A_{i, i} - L_{i, :}L_{i, :}^T$\n",
    "\n",
    "> $A_{j, i} = A_{j, i} - L_{i, :}L_{j, :}^T$\n",
    "\n",
    "> $L_{i, i} = \\sqrt { A_{i, i} }$\n",
    "\n",
    "> $L_{i+1:n, i} = \\frac{A_{i+1:n, i}}{L_{i, i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 1]\n",
      " [1 2 1]\n",
      " [1 1 2]]\n",
      "\n",
      "[[ 1.41421356  0.          0.        ]\n",
      " [ 0.70710678  1.22474487  0.        ]\n",
      " [ 0.70710678  0.40824829  1.15470054]]\n",
      "\n",
      "[[ 2.  1.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [ 1.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def my_cholesky(A):\n",
    "    L = np.zeros(A.shape)\n",
    "    \n",
    "    n = A.shape[0]\n",
    "    \n",
    "    for i in range(n):\n",
    "        L[i, i] = math.sqrt(A[i, i] - L[i, :].dot(L[i, :].T))\n",
    "        \n",
    "        for j in range(i+1, n):\n",
    "            L[j, i] = (A[j, i] - L[i, :].dot(L[j, :].T)) / L[i, i]\n",
    "            \n",
    "    return L\n",
    "            \n",
    "A = np.array([[2, 1, 1], [1, 2, 1], [1, 1, 2]])\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "L = my_cholesky(A)\n",
    "print(L)\n",
    "print()\n",
    "\n",
    "print(L.dot(L.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Application\n",
    "\n",
    "If $A$ is real and positive definite, to solve, \n",
    "\n",
    "> $Ax = b$\n",
    "\n",
    "Using Cholesky decomposition (lower triangular), \n",
    "\n",
    "> $A = LL^T$\n",
    "\n",
    "Thus, the problem becomes, \n",
    "\n",
    "> $LL^Tx = b$\n",
    "\n",
    "First, solve, \n",
    "\n",
    "> $Ly = b, L^Tx = y$\n",
    "\n",
    "Finally, solve,\n",
    "\n",
    "> $L^T x = y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.41421356  0.          0.        ]\n",
      " [ 0.70710678  1.22474487  0.        ]\n",
      " [ 0.70710678  0.40824829  1.15470054]]\n",
      "\n",
      "[[ 2.  1.  1.]\n",
      " [ 1.  2.  1.]\n",
      " [ 1.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import cholesky\n",
    "\n",
    "# A must be a positive-definite square matrix.\n",
    "# A must be real positive symmetic.\n",
    "A = np.array([[2, 1, 1], [1, 2, 1], [1, 1, 2]])\n",
    "\n",
    "L = cholesky(A, lower=True)\n",
    "print(L)\n",
    "print()\n",
    "\n",
    "B = L.dot(L.T)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Singular Value Decomposition\n",
    "\n",
    "## 4.0 EigenValue & EigenVector\n",
    "\n",
    "> $A x = \\lambda x$, \n",
    "\n",
    "+ Equation for eigenvalue $\\lambda$, \n",
    "\n",
    "> $det(A - \\lambda I) = 0$, \n",
    "\n",
    "+ Equation for eigenvector $x$, \n",
    "\n",
    "> $(A - \\lambda I) x = 0$\n",
    "\n",
    "## 4.1 Diagonalizing Matrix\n",
    "\n",
    "For eigen matrix $S$ made up of eigenvector \n",
    "> $S = [x_1, x_2, ..., x_n]$,\n",
    "\n",
    "and a diagonal matrix $\\Lambda$ made up of eigenvalue $\\lambda_n$, \n",
    "$\\Lambda_{i,i} = \\lambda_{i}$, \n",
    "\n",
    "> $A S = A [x_1, x_2, ..., x_n]$\n",
    "\n",
    "> $= [A x_1, A x_2, ..., A x_n]$\n",
    "\n",
    "> $= [\\lambda_1 x_1, \\lambda_2 x_2, ..., \\lambda_n x_n]$\n",
    "\n",
    "> $= [x_1, x_2, ..., x_n] \\Lambda$\n",
    "\n",
    "> $= S \\Lambda$\n",
    "\n",
    "$\\Longrightarrow$\n",
    "\n",
    "> $\\Lambda = S^{-1}AS$\n",
    "\n",
    "Any matrix that has no repeated eigenvalues can be diagonalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Symmetric Matrix\n",
    "\n",
    "If $A$ is a symmetric matrix, $A = A^T$, if $A$ is not singular, \n",
    "\n",
    "> $A = S \\Lambda S^{-1}$\n",
    "\n",
    "> $A^T = (S \\Lambda S^{-1})^T = {S^{-1}}^T \\Lambda S^T, \\Lambda^T = \\Lambda$\n",
    "\n",
    "Because $A = A^T$, \n",
    "\n",
    "> $S \\Lambda S^{-1} = (S^{-1})^T \\Lambda S^T = (S^T)^{-1} \\Lambda S^T$\n",
    "\n",
    "<b>Possibly</b>, \n",
    "\n",
    "> $S^{-1} = S^T, \\Longrightarrow S^T S = I$\n",
    "\n",
    "> $S = (S^T)^{-1}, \\Longrightarrow S S^T = I$\n",
    "\n",
    "Thus, a symmetric matrix <b>can</b> be decomposited to orthogonal eigenvectors.\n",
    "\n",
    "> $A = A^T$\n",
    "\n",
    "> $A = Q \\Lambda Q^T, Q^T = Q^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Positive Definite Matrix\n",
    "\n",
    "+ $A$ is <b>Positive Definite</b> if $x^T A x > 0$ for every nonzero $x$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.4 SVD\n",
    "\n",
    "If a matrix $A$ is symmetric, it can be diagonalized by the eigenvectors.\n",
    "\n",
    "> $A = S \\Lambda S^{-1}$\n",
    "\n",
    "But if $A$ is singular, it cannot be decomposited.\n",
    "\n",
    "If $AA^T$ and $AA^T$ is nonsingular, \n",
    "let $U$ and $V$ be the eigenvectors of $AA^T$ and $A^TA$.\n",
    "\n",
    "$(AA^T)^T = AA^T$, thus, $AA^T$ and $AA^T$ is symmetric matrix,\n",
    "$U$ and $V$ can be chosen orthogonal,\n",
    "\n",
    "> $AA^T = U \\Lambda_1 U^{-1} = U \\Lambda_1 U^T$\n",
    "\n",
    "> $A^TA = V \\Lambda_2 V^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ SVD\n",
    "\n",
    "For $A \\in \\mathbb{R}^{m \\times n}$ and \n",
    "orthogonal matrix $U \\in \\mathbb{R}^{m \\times m}$ and $V \\in \\mathbb{R}^{n \\times n}$,\n",
    "\n",
    "which is the eigenvectors of $AA^T \\in \\mathbb{R}^{m \\times m}$ and $A^TA \\in \\mathbb{R}^{n \\times n}$ respectively, \n",
    "\n",
    "$\\Sigma \\in \\mathbb{R}^{m \\times n}$ is a diagonal matrix, whose diagonal values are the eigenvalues of $M$ (often sorted descended),\n",
    "\n",
    "> $A = U \\Sigma V^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3863177  -0.92236578]\n",
      " [-0.92236578  0.3863177 ]]\n",
      "\n",
      "[ 9.508032    0.77286964]\n",
      "\n",
      "[[-0.42866713 -0.56630692 -0.7039467 ]\n",
      " [ 0.80596391  0.11238241 -0.58119908]\n",
      " [ 0.40824829 -0.81649658  0.40824829]]\n",
      "\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import svd\n",
    "\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]]) # (2 * 3)\n",
    "\n",
    "U, Sigma, V = svd(A)\n",
    "print(U)\n",
    "print()\n",
    "\n",
    "print(Sigma)\n",
    "print()\n",
    "\n",
    "print(V)\n",
    "print()\n",
    "\n",
    "# To save storage, diagonal matrix Sigma can be sorted in an array.\n",
    "filled_Sigma = np.zeros(A.shape)\n",
    "\n",
    "for i in range(Sigma.size):\n",
    "    filled_Sigma[i][i] = Sigma[i]\n",
    "\n",
    "B = U.dot(filled_Sigma).dot(V)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
