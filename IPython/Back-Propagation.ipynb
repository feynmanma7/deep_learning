{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Back Propagation</h1>\n",
    "\n",
    "# 0. 多层感知机\n",
    "\n",
    "以多层感知机为例，BP（反向传播）是解决MLP问题的一种方法。\n",
    "\n",
    "## 0.0 网络层\n",
    "\n",
    "> 一共$L+2$层的多层感知机，包含输入层、$L$个隐含层以及输出层。分别定义为第$0$层，第$l\\in\\{1,2,...,L-L\\}$层以及第$L+1$层；\n",
    "\n",
    "> + 输入层：$X \\in \\mathbb{R}^{N \\times M}$，共$N$个样本，每个样本$M$维；\n",
    "\n",
    "> + 隐含层：隐含层$l$的节点个数为$n\\_unit^{(l)}$，输入为$input^{(l)}$，输出为$output^{(l)}$；该层权重定义为上一层节点$i$到当前层节点$j$的权重$w_{ij}^{(l)} \\in \\mathbb{R}^{n\\_unit^{(l-1)} \\times n\\_unit^{(l)}}$，偏置为$b^{(l)} \\in \\mathbb{R}^{n\\_unit^{(l)}}$；\n",
    "\n",
    "> + 输出层：节点个数为$n\\_unit^{(L+1)}$，输入为$input^{(L+1)}$，输出为$output^{(L+1)}$；权重定义为最后一个隐含层的节点$i$到输出层的节点$j$的权重$w_{ij}^{(L+1)} \\in \\mathbb{R}^{n\\_unit^{(L)} \\times n\\_unit^{(L+1)}}$，偏置为$b^{(L+1)} \\in \\mathbb{R}^{n\\_unit^{(L+1)}}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 输入输出\n",
    "\n",
    "> + 输入层：输入层输入、输出一样，都是$X \\in \\mathbb{R}^{N \\times M}$;\n",
    "\n",
    "> + 隐含层：第$l$层第$i$个节点输入为$input_i^{(l)} = \\sum_j^{n\\_unit^{(l-1)}} w_{ji}^{(l)} output_j^{(l-1)} + b^{(l)}$，输出为$output_i^{(l)} = activation(input_i^{(l)})$；\n",
    "\n",
    "> + 输出层：第$i$个节点输入为$input_i^{(L+1)} = \\sum_j^{n\\_unit^{(L)}} w_{ji}^{(L+1)} output_j^{(L)} + b^{(L+1)}$，输出为$output_i^{(L+1)} = activation(input_i^{(L+1)})$；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Forward Propagation\n",
    "\n",
    "对于mini_batch数据$X \\in \\mathbb{R}^{N \\times M}$，前向传播得到所有隐含层以及输出层的输入输出。\n",
    "\n",
    "考虑向量计算形式，对于$l \\in \\{1, 2, ..., L, L+1\\}$，\n",
    "\n",
    "> + $output^{(0)} = X$ \n",
    "\n",
    "> + $input^{(l)} = output^{(l-1)} \\times w^{(l)} + b^{(l)}$\n",
    "\n",
    "> + $output^{(l)} = activation(input^{(l)})$\n",
    "\n",
    "激活函数选择sigmoid函数，$\\frac{\\partial{activation(x)}}{\\partial{x}} = activation(x) * (1 - activation(x))$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Back Propagation Error\n",
    "\n",
    "不管是分类还是回归问题，训练的时候如果预测与预期（真实值）不符，就需要调整网络的权重。对于网络中的每一条边，都需要根据最终的误差进行微调，从而需要计算最终误差关于网络权重的偏导数。\n",
    "\n",
    "$N$个样本的mini_batch误差：\n",
    "> $\\Delta E = \\frac{1}{N}\\sum_{n=1}^{N} \\left(\\frac{1}{2} \\sum_{j=1}^{n\\_unit^{(L+1)}} (y_{nj} - t_{nj})^2\\right)$\n",
    "\n",
    "考虑向量计算形式，对于$l \\in \\{L+1, L, ..., 2, 1\\}$，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1.0 输出层\n",
    "\n",
    "最后一个隐含层的节点$i$到输出层的节点$j$之间的权重$w_{ij}^{(L+1)}$，\n",
    "> $\\frac{\\partial{\\Delta E}} {\\partial{w_{ij}^{(L+1)}}}\n",
    " = \\frac{\\partial{\\Delta E}} {\\partial{input_j^{(L+1)}}} \n",
    "   \\frac{\\partial{input_j^{(L+1)}}} {\\partial{w_{ij}^{(L+1)}}}$\n",
    "   \n",
    "> 令 $\\delta_j^{(l)} = \\frac{\\partial{\\Delta E}} {\\partial{input_j^{(l)}}} $ ,\n",
    "\n",
    "> $\\delta_j^{(L+1)} = (y_j - t_j) * \\sigma(input_j^{(l)}) * (1 - \\sigma(input_j^{(l)}))$,\n",
    "\n",
    "> $\\frac{\\partial{\\Delta E}} {\\partial{w_{ij}^{(L+1)}}}\n",
    " = \\delta_j^{(l)} * output_i^{(L)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 隐含层\n",
    "\n",
    "隐含层$l-1$的节点$i$到$l$层的节点$j$之间的权重$w_{ij}^{(l)}$，\n",
    "\n",
    "> $\\frac{\\partial{\\Delta E}} {\\partial{w_{ij}^{(l)}}}\n",
    "= \\frac{\\partial{\\Delta E}} {\\partial{input_j^{(l)}}} \n",
    "\\frac{\\partial{input_j^{(l)}}} {\\partial{w_{ij}^{(l)}}}\n",
    "= \\delta_j^{(l)} * output_i^{(l+1)}$\n",
    "\n",
    "> $\\delta_j^{(l)} =\n",
    "\\frac{\\partial{\\Delta E}} {\\partial{input_j^{(l)}}} \n",
    "= \\sum_{k=1}^{n\\_unit^{(l+1)}} \n",
    "\\frac{\\partial{\\Delta E}} {\\partial{input_k^{(l+1)}}} \n",
    "\\frac{{\\partial{input_k^{(l+1)}}}} {{\\partial{input_j^{(l)}}}}$\n",
    "\n",
    "> $= \\sum_{k=1}^{n\\_unit^{(l+1)}} \n",
    "\\delta_k^{(l+1)}\n",
    "* w_{kj} \\sigma^{'}(input_j^{(l)})\n",
    "$\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
